{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Deploying a Watson Machine Learning Model with Python"}, {"metadata": {}, "cell_type": "markdown", "source": "In this article, I build a machine learning model in a jupyter notebook inside Watson Studio, then deploy the model programmatically using python code to Watson Machine Learning (WML). Doing so allows you to incorporate the machine learning model into applications via an API. \n\nI designed this tutorial for those with some knowledge of python, machine learning, Watson Studio, cloud object storage, and IBM Cloud. \nAlso, this tutorial is specific to IBM Public cloud environments (Software as a Service (SaaS)).   Versions of Watson Studio running on a Kubernetes cluster or locally on your desktop will require different WML model deployment procedures."}, {"metadata": {}, "cell_type": "markdown", "source": "## Table of Contents"}, {"metadata": {}, "cell_type": "markdown", "source": "1. [Getting Setup](#10)<br>\n2. [Prerequisites](#20)<br>\n3. [Research and set WML parameters](#30)<br>\n    3.1 [ Find the supported Watson Studio Runtime and python version](#31)<br>\n    3.2 [Find the supported version of you model](#32)<br>\n    3.3 [Generate an API Key](#33)<br>\n    3.4 [Find the endpoint of your Watson Machine learning service](#34)<br>\n    3.5 [Name you model](#35)<br>\n    \n4. [Build a machine learning model](#40)<br>\n5. [Deploy the model](#50)<br>"}, {"metadata": {}, "cell_type": "markdown", "source": "### 1.0 Getting Setup.<a id=\"10\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "Establish Libraries"}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\nimport numpy as np\nimport pandas as pd\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Ensure WML is up to date."}, {"metadata": {}, "cell_type": "code", "source": "!pip install -U ibm-watson-machine-learning", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "###  2.0 Prerequisites. <a id=\"20\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "This tutorial assumes that you have some knowledge of Watson Studio and Cloud Pak for Data on IBM Cloud.  Specifically, it assumes that you can do the following.  \n1.  Create an IBMid.  https://www.ibm.com/account/reg/us-en/signup?formid=urx-19776\n2.  Provision an instance of Watson Studio.  https://dataplatform.cloud.ibm.com/docs/content/svc-welcome/wsl.html?audience=wdp\n3.  Provision an instance of Watson Machine Learning.  https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/WMLServiceInstance.html\n3.  Set up a deployment space inside cloud pak for data.  https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-space-create.html\n\n\nIf you do not know how to do these things, don't worry.  There is plenty of good documentation on how to do so.  Please follow the links provided.  If you know how to do these things but still need to, please do so now."}, {"metadata": {}, "cell_type": "markdown", "source": "### 3.0 Research and set WML parameters. <a id=\"30\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "Before starting, there are five parameters to locate for successful model deployment. These include the following.\n\n1. The supported Watson Studio Runtime and Python version.\n2. The supported version of your model.\n3. An API Key.\n4. The end point of your Watson Machine Learning service.\n5. The name of your model."}, {"metadata": {}, "cell_type": "markdown", "source": "#### 3.1 Find the supported Watson Studio Runtime and python version. <a id=\"31\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "\n\nBased on your machine learning model,  there is one and only one appropriate Watson Studio Runtime version and Python version.\n\nThe following link details these versions in detail.  \nhttps://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=specifications-software-hardware-deployments\n\n\n\n<strong>When navigating this page, please ENSURE YOU HAVE THE RIGHT VERSION of Cloud Pak for Data.</strong>  A pull-down menu in the top left corner of the web page alters the documentation based on the Cloud Pak for Data version.  \n\nIn this example, I use an xgboost model.  Based on the documentation, xgboost is currently only supported for python version 3.9 (3.10 is the most current version as I am writing this).  The supported runtime for this model is 22.1.  Please copy the text stating the correct runtime and python version and paste it below as a python object.  The text must be precisely the same as on the website."}, {"metadata": {}, "cell_type": "code", "source": "runtime_version='runtime-22.1-py3.9'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### 3.2 Find the supported version of your model. <a id=\"32\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "This link also details the supported version of your model.\n\nhttps://www.ibm.com/docs/en/cloud-paks/cp-data/4.0?topic=specifications-software-hardware-deployments\n\nFind the appropriate model_type, and copy and paste the model_type from the web page above into a python object.  For me, the model type is 'xgboost_1.5.'"}, {"metadata": {}, "cell_type": "code", "source": "model_type='xgboost_1.5'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<strong>After identifying the model_type, runtime, and python version, Ensure that the runtime and python version for your Jupyter notebook is what it needs to be.</strong>\n\n\nYou can check your notebook's runtime and python versions by clicking on the information icon (an i with a circle around it) in the top right corner.  You can also change the environment here is as well.  I have to ensure that the python software version is 3.9 and the runtime is 22.1.\n\n"}, {"metadata": {}, "cell_type": "markdown", "source": "#### 3.3 Generate an API Key. <a id=\"33\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "How to Generate an API key is well documented.  Please see the following link.\n\nhttps://www.ibm.com/docs/en/app-connect/containers_cd?topic=servers-creating-cloud-api-key\n\nWhen you get the API, paste it as a python object in the cell below."}, {"metadata": {}, "cell_type": "code", "source": "api_key='XXXXXXXX'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### 3.4 Find the endpoint of your Watson Machine learning service. <a id=\"34\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "When creating a Watson Machine Learning service, you choose where to create it. You can choose Dallas, London, Frankfurt, or Tokyo. If you don't remember, click on the hamburger menu in the top left corner, then go to \"Services Instances .\"Under \"Services Instances,\" find the WML service you want to use, which details the location. Make a note of the following endpoint based on the site of your service.  \n\n\nDallas: https://us-south.ml.cloud.ibm.com\n\nLondon - https://eu-gb.ml.cloud.ibm.com\n\nFrankfurt - https://eu-de.ml.cloud.ibm.com\n\nTokyo - https://jp-tok.ml.cloud.ibm.com\n\n\nYou can find these URLs on the web here. https://cloud.ibm.com/apidocs/machine-learning\n\nCreate a python object that defines the correct WML end point. For me, it is Dallas."}, {"metadata": {}, "cell_type": "code", "source": "endpoint='https://us-south.ml.cloud.ibm.com'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### 3.5 Name you model <a id=\"35\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "The model name is how identifies the model systematically inside the IBM cloud.  It can be anything, but ideally, it describes the model.  I will use \"High/Low Midi-chlorians Classifier V1.\""}, {"metadata": {}, "cell_type": "code", "source": "name='High/Low Midi-chlorians Classifier V1'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 4.0 Build a machine learning model <a id=\"40\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "Import data from google drive"}, {"metadata": {}, "cell_type": "code", "source": "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt\\\n    \\--keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID'\\\n    \\-O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1dNDmrhlocDog23mXntpS0OdMMAPC5848\" -O balanced.csv && rm -rf /tmp/cookies.txt\n\n\n\ndf_balanced = pd.read_csv(\"balanced.csv\", sep=\",\", header=0)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Examine the rows and column of the data"}, {"metadata": {}, "cell_type": "code", "source": "df_balanced.shape", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "The data we use in the following steps is fictitious and not the point of the exercise, so I will not worry about describing it in much detail.  We don't need the complete data set to show how to deploy a model to WML.  Thus, I will take a .5% random sample and reduce the number of columns."}, {"metadata": {}, "cell_type": "code", "source": "df_balanced=df_balanced[['FAILURE_TARGET', 'AGE_OF_EQUIPMENT', 'S15', 'S17', 'S13', 'S5', 'S16',\n       'S19', 'S18', 'S8']].copy()\n\nnp.random.seed(33)\ndf_balanced['wookie'] = (np.random.randint(0, 10000, df_balanced.shape[0]))/10000\n\n\ndf_balanced=df_balanced[df_balanced['wookie']<.005]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Define the features, dependent variable, and independent variables."}, {"metadata": {}, "cell_type": "code", "source": "features = [x for x in df_balanced.columns if x not in ['FAILURE_TARGET']]  \ndependent=pd.DataFrame(df_balanced['FAILURE_TARGET'])\n\nindependent=df_balanced.drop(columns=['FAILURE_TARGET'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Specify the algorithm."}, {"metadata": {}, "cell_type": "code", "source": "from xgboost.sklearn import XGBClassifier", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "xgb0 = XGBClassifier(objective = 'binary:logistic',use_label_encoder=False);", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Build the model."}, {"metadata": {}, "cell_type": "code", "source": "xgb0.fit(independent, dependent, eval_metric='error')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 5.0 Deploy the model <a id=\"50\"></a>"}, {"metadata": {}, "cell_type": "markdown", "source": "Build credentials for the WML service using the API Key and endpoint."}, {"metadata": {}, "cell_type": "code", "source": "\nwml_credentials = {\n                  \"apikey\":api_key,\n                  \"url\":endpoint\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, import the API client from the WML python library and submit your WML credentials."}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\n\nclient = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Next, examine the deployment spaces available.  Again, this tutorial does not cover how to create a deployment space.  Fortunately, this is well documented.\n\nSelect the deployment space you want to use by copying the ID for the deployment space and pasting it into a python object.  I only have one, Dagobah, so I will use it."}, {"metadata": {}, "cell_type": "code", "source": "client.spaces.list(limit=10)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_id = 'XXXXXXXXXXX'", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Set the default space in the WML client.  It should say 'SUCCESS' if you do it right."}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_id)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Set the software specifications to the appropriate runtime and versions we established in section 3."}, {"metadata": {}, "cell_type": "code", "source": "sofware_spec_uid = client.software_specifications.get_id_by_name(runtime_version)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Define the metadata of the model."}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n            client.repository.ModelMetaNames.NAME: name,\n            client.repository.ModelMetaNames.TYPE: model_type,\n            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Below, make sure you specify the name of the machine learning model.  I named the machine learning model xgb0. \n\nFrom  a previous line, \"xgb0 = XGBClassifier(objective = 'binary:logistic',use_label_encoder=False);\"\n\n\nWrite the model to a WML repository with the appropriate metadata."}, {"metadata": {}, "cell_type": "code", "source": "published_model = client.repository.store_model(\n    model=xgb0,\n    meta_props=metadata,\n    training_data=independent,\n    training_target=dependent)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "View the model details in a JSON."}, {"metadata": {}, "cell_type": "code", "source": "import json\n\npublished_model_uid = client.repository.get_model_id(published_model)\nmodel_details = client.repository.get_details(published_model_uid)\nprint(json.dumps(model_details, indent=2))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "List all of the models saved to the repository.  We should see the model we created and saved at the top."}, {"metadata": {}, "cell_type": "code", "source": "models_details = client.repository.list_models()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Deploy the model to the Watson Machine Learning service so other applications can use it."}, {"metadata": {}, "cell_type": "code", "source": "metadata = {\n    client.deployments.ConfigurationMetaNames.NAME: name,\n    client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\ncreated_deployment = client.deployments.create(published_model_uid, meta_props=metadata)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}